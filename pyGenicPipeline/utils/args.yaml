# This file holds default parameters for input to each function, as well as all the parameters, so that a user can
# request via ArgMaker the arguments they need to change for a given method to run without having to worry about
# arguments that will not be required. It can also be used as part of the GUI pipeline, when it comes to validate if the
# args passed via the GUI have meet the minimum requirements for the method.



all_args:

  ## LOAD ARGUMENTS ####################################################################################################
  # Project or output directory
  Working_Directory: null

  # The operation to be run, can take a string if the method name or a dict of operations where only one element is true
  Operation: null

  # Some operations will require a path to a set file
  Load_File: null

  # Other operations will require a path to a directory. (Some may need both, hence them being separate)
  Load_Directory: null

  # .bed or .bgen are only valid options. The '.' is required
  Load_Type: null

  # Use the PySnpTools bgen reader rather than pyGenicParser, defaults to True
  PySnpTools_Bgen: True

  # Most pipeline files are run by chromosome. Provide an int to this for a given file
  Target_Chromosome: null

  # When using certain pipelines you will need to provide a link to individuals whom are genetically un-related to this
  # parameter as a csv like file WITHOUT file headers where the first column is the FID and the second the IID
  Reference_Panel: null

  # Many large processes can be chunked into smaller sub processes to save memory, this is the maximum size you
  #  want a chunk be. Defaults to 10000
  Iter_Size: 10000

  # Some process may be able to use a default args list to make additional files, set a path to the yaml file that
  # contains these defaults here
  Default_Args: null

  ## SHELL ARGUMENTS ###################################################################################################

  # Takes the values of slurm, qsub, and null
  Job_Scheduler: null

  # Partition to use when using slurm
  Partition: null

  # Number of nodes to use, defaults to 1
  Nodes: 1

  # Job time via Job_Scheduler
  Job_Time: "00:05:00"

  # Amount of memory to allocate via Job_Memory, defaults to 100m
  Job_Memory: "100m"

  # Path to plink on sever
  Plink_Path: null

  # Path to qctoolv2 on sever
  QCTool_Path: null

  # Path to the compiled bgenix folder in build/apps/bgenix
  BGENIX_Path: null

  ## PolyGenic Score Pipeline Arguments ################################################################################
  ### pgs_clean_summary_stats args #####################################################################################

  # If the user has summary header information not within our own testing list, then they can add it here
  Custom_Summary_Header: null

  # A path to summary statistics, which will be handled differently than other files
  Summary_Path: null

  # The number of samples in the summary statistics
  Summary_Sample_Size: null

  # The effect type within the summary statistics file
  Summary_Effect_Type: null

  # If the user wants to only use HapMap3 snps then they need to provide a file to those snps
  HapMap3: null

  # If the user wants to compute z scores from summary file
  Z_Scores: null

  ### pgs_filter_snps args #############################################################################################

  # Filter out snps in long range LD if set to True
  Filter_Long_Range_LD: null

  # The minimum Minor allele frequency, defaults to 0.01
  Filter_Min_Maf: 0.01

  # The maximum Frequency Discrepancy, defaults to 0.1
  Filter_Max_Freq_Discrepancy: 0.1

  # LD args ############################################################################################################

  # The Linkage disequilibrium (LD) radius to create iteration windows of snps to correct for LD.
  LD_Radius: null

  # If you want to provide pre-calculate heritability estimates you can do so per chromosome via passing a dict of type
  # Chromosome_Number: herit, if you want to distribute heritability across chromosomes provide a float, or if you want
  #it to be calculated then leave as None
  Heritability_Calculated: null

  # Score args #########################################################################################################
  # Path to covariates for correction of scores
  "Covariates": null

  # Path to phenotype for correction of scores
  "Phenotype": null

# For writing new yaml files with human readable comments, here the comments for all args are stored so they can be
# accessed via keys
Arg_Descriptions:
  ## LOAD ARGUMENTS ####################################################################################################
  Working_Directory: Project or output directory

  Operation: >-
    The operation to be run, can take a string if the method name or a dict of operations where only one element is true

  Load_File: Some operations will require a path to a set file

  Load_Directory: >-
    Other operations will require a path to a directory, and some may need both hence them being separate

  Load_Type: .bed or .bgen are only valid options. The '.' is required

  PySnpTools_Bgen: Use the PySnpTools bgen reader rather than pyGenicParser, defaults to True

  Target_Chromosome: Most pipeline files are run by chromosome. Provide an int to this for a given file

  Reference_Panel: >-
    When using certain pipelines you will need to provide a link to individuals whom are genetically un-related to this
    parameter as a csv like file WITHOUT file headers where the first column is the FID and the second the IID

  Iter_Size: >-
    Many large processes can be chunked into smaller sub processes to save memory, this is the maximum size you want a
    chunk be. Defaults to 10000

  Default_Args: >-
    Some process may be able to use a default args list to make additional files, set a path to the yaml file that
    contains these defaults here

  ## SHELL ARGUMENTS ###################################################################################################

  Job_Scheduler: Takes the values of slurm, qsub, and null

  Partition: Partition to use when using slurm

  Nodes: Number of nodes to use, defaults to 1

  Job_Time: Job time via Job_Scheduler

  Job_Memory: Amount of memory to allocate via Job_Memory, defaults to 100m

  Plink_Path: Path to plink on sever, has a default based on bc4 bristol

  QCTool_Path: Path to qctoolv2 on sever, has a default based on bc4 bristol

  BGENIX_Path: Path to the compiled bgenix folder in build/apps/bgenix

  ## PolyGenic Score Pipeline Arguments ################################################################################
  ### pgs_clean_summary_stats args #####################################################################################

  Summary_Path: >-
    Some Operations will require a path to summary statistics, which will be handled differently than other files

  Summary_Sample_Size: The number of samples in the summary statistics

  Custom_Summary_Header: >-
    If the user has summary header information not within our own testing list, then they can add it here

  Summary_Effect_Type: The effect type within the summary statistics file

  HapMap3: If the user wants to only use HapMap3 snps then they need to provide a file to those snps

  Z_Scores: If the user wants to compute z scores from summary file

  ### pgs_filter_snps args #############################################################################################

  Filter_Long_Range_LD: Filter out snps in long range LD if set to True

  Filter_Min_Maf: The minimum Minor allele frequency, defaults to 0.01

  Filter_Max_Freq_Discrepancy: The maximum Frequency Discrepancy, defaults to 0.1

  # LD args ############################################################################################################

  LD_Radius: The Linkage disequilibrium (LD) radius to create iteration windows of snps to correct for LD.

  Heritability_Calculated: >-
    If you want to provide pre-calculate heritability estimates you can do so per chromosome via passing a dict of type
    Chromosome_Number: herit, if you want to distribute heritability across chromosomes provide a float, or if you want
    it to be calculated then leave as None

  # Score args #########################################################################################################
  "Covariates": Path to covariates for correction of scores

  "Phenotype": Path to phenotype for correction of scores


# Whilst default summary header keys have been extract from LDPred, it is possible they are not the ones within the
# summary statistics the end user is using. This allows them to provide a custom set to be used in lue of defaults
custom_summary_header_keys:

  # Chromosomes header, optional
  Chromosome: null

  # snp/variant ID header, Mandatory
  snp_id: null

  # Effect Allele header, Mandatory
  Effect_Allele: null

  # Alt Allele header, Mandatory
  Alt_Allele: null

  # Base-Pair Position header, Mandatory
  BP_Position: null

  # P value header, Mandatory
  P_Value: null

  # Effect Size header, Mandatory
  Effect_Size: null

  # Minor Allele frequency (MAF) header, Optional
  Minor_Allele_Freq: null

  # INFO  header, Optional
  Info: null

  # Standard errors header, Optional
  Standard_Errors: null

  # If working with summary statistics from Psychiatric Genomics Consortium then you will also need to provide these
  # headers which represent the case-control frequency and number of individuals.
  Case_Freq: null
  Control_Freq: null
  Case_N: null
  Control_N: null

# Valid operations by operation group with each operation being given its description as its value
Operations:
  File_Support:
    Description: >-
      These methods are designed to aid you format raw genetic data into different file formats or sizes

    split_bed_by_chromosome:
      Description: >-
        This will generate a shell script using plink to split a bed file into the respective chromosomes
      Mandatory: ["Working_Directory", "Load_File", "Operation", "Job_Scheduler", "Partition", "QCTool_Path",
                  "BGENIX_Path"]
      Optional: ["Nodes", "Job_Time", "Job_Memory"]

    convert_to_bgen:
      Description: >-
        This will create a script to utilise qctoolv2 to convert plink .bed to .bgen files.
      Mandatory: ["Working_Directory", "Load_File", "Operation", "Job_Scheduler", "Partition", "Plink_Path"]
      Optional: ["Nodes", "Job_Time", "Job_Memory"]

  PGS_Pipeline:
    Description: >-
      These methods are designed to aid you to construct polygenic scores
    construct_polygenic_score:
      Description: >-
        This will help you setup all the parameters you need to construct a polygenic score, this will make all the
        files for all the operations that are below, but you can make them individually or run them separately if you
        want something specific from them.

      Mandatory: ["Working_Directory", "Operation", "Job_Scheduler", "Partition", "Load_Type", "PySnpTools_Bgen",
                  "Target_Chromosome", "Load_Directory", "Reference_Panel", "Iter_Size", "Summary_Path",
                  "Summary_Sample_Size", "Summary_Effect_Type", "HapMap3", "Z_Scores"]
      Optional: ["Nodes", "Job_Time", "Job_Memory", "Custom_Summary_Header"]

    pgs_clean_summary_stats:
      Description: >-
        This will take the summary statistics and access the validatable snps, found by cross referencing the genetic
        validation constructed from the reference file, and clean them of possible errors. It then returns an ordered on
        base pair position dictionary of information required for constructing poly-genetic scores and by default writes
        this information to a csv.

      Mandatory: ["Working_Directory", "Operation", "Job_Scheduler", "Partition", "Load_Type", "PySnpTools_Bgen",
                  "Target_Chromosome", "Load_Directory", "Reference_Panel", "Summary_Path", "Summary_Sample_Size",
                  "Summary_Effect_Type", "HapMap3", "Z_Scores"]
      Optional: ["Nodes", "Job_Time", "Job_Memory", "Custom_Summary_Header"]

    pgs_filter_snps:
      Description: >-
        From our cleaned summary statistics we can construct a set of information for our validation and reference
        genetic samples. These samples need there raw snps to be loaded, and then we can use these to calculate genetic
        frequencies and standard deviations.

        If we have information on summary frequencies, the user has specified a maf_min or wants to filter snps in long
        range LD then we can filter those out. This process will always filter out monomorphic snps.

      Mandatory: ["Working_Directory", "Operation", "Job_Scheduler", "Partition", "Load_Type", "PySnpTools_Bgen",
                  "Target_Chromosome", "Load_Directory", "Reference_Panel", "Iter_Size", "Filter_Min_Maf",
                  "Filter_Max_Freq_Discrepancy", "Filter_Long_Range_LD"]
      Optional: ["Nodes", "Job_Time", "Job_Memory"]

    suggest_ld_radius:
      Description: >-
        This will use the snp_count / 3000 formula from LD-pred to get a rough LD radius

      Mandatory: ["Working_Directory", "Operation", "Job_Scheduler", "Partition", "Load_Type", "PySnpTools_Bgen",
                  "Target_Chromosome", "Load_Directory", "Reference_Panel"]
      Optional: ["Nodes", "Job_Time", "Job_Memory"]

    pgs_calculate_ld:
      Description: >-
        This will calculate the chromosome specific LD information which will be used later to construct genome_wide LD
        information, whilst also saving the values of the normalised Snps and standard errors

      Mandatory: ["Working_Directory", "Operation", "Job_Scheduler", "Partition", "Load_Type", "PySnpTools_Bgen",
                  "Target_Chromosome", "Load_Directory", "Reference_Panel", "LD_Radius"]
      Optional: ["Nodes", "Job_Time", "Job_Memory"]

    calculate_genome_wide_heritability:
      Description: >-
        Once we have cleaned our data sets, we can store the genome wide data along side with some individual
        chromosome information that does not take the form of lists, in a yaml config file.

      Mandatory: ["Working_Directory", "Operation", "Job_Scheduler", "Partition", "Load_Type", "PySnpTools_Bgen",
                  "Target_Chromosome", "Load_Directory", "Reference_Panel", "LD_Radius", "Summary_Sample_Size"]
      Optional: ["Nodes", "Job_Time", "Job_Memory"]

    pgs_infinitesimal:
      Description: >-
        This will weight the beta values conditional on LD using infinitesimal shrinkage
      Mandatory: []
      Optional: []

    pgs_scores:
      Description: >-
        This will construct the pgs for a given weight beta type, such as infinitesimal, within this chromosome

      Mandatory: []
      Optional: []

    aggregate_scores:
      Description: >-
        This will combine the scores found by chromosome into a single file

      Mandatory: []
      Optional: []
